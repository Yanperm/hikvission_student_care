"""
Advanced Face Recognition with Deep Learning
‡πÉ‡∏ä‡πâ face_recognition library (dlib) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö accuracy ‡∏™‡∏π‡∏á 95-99%
"""

import face_recognition
import numpy as np
import cv2
import os
import pickle
from datetime import datetime

class AdvancedFaceRecognition:
    def __init__(self, data_dir='data/students'):
        self.data_dir = data_dir
        self.known_faces = []
        self.known_ids = []
        self.model_file = 'data/face_model.pkl'
        
    def train(self, students):
        """‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å‡∏£‡∏π‡∏õ‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô"""
        print("ü§ñ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• AI...")
        self.known_faces = []
        self.known_ids = []
        
        for student in students:
            image_path = student.get('image_path')
            if image_path and os.path.exists(image_path):
                try:
                    image = face_recognition.load_image_file(image_path)
                    encodings = face_recognition.face_encodings(image)
                    
                    if encodings:
                        self.known_faces.append(encodings[0])
                        self.known_ids.append(student['student_id'])
                        print(f"‚úÖ ‡πÄ‡∏ó‡∏£‡∏ô: {student['name']}")
                except Exception as e:
                    print(f"‚ùå ‡∏Ç‡πâ‡∏≤‡∏°‡πÑ‡∏ü‡∏•‡πå: {image_path} - {e}")
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
        self.save_model()
        print(f"‚úÖ ‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à! ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô: {len(self.known_faces)} ‡∏Ñ‡∏ô")
        
    def save_model(self):
        """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•"""
        os.makedirs('data', exist_ok=True)
        with open(self.model_file, 'wb') as f:
            pickle.dump({
                'faces': self.known_faces,
                'ids': self.known_ids
            }, f)
        print(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•: {self.model_file}")
    
    def load_model(self):
        """‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•"""
        if os.path.exists(self.model_file):
            with open(self.model_file, 'rb') as f:
                data = pickle.load(f)
                self.known_faces = data['faces']
                self.known_ids = data['ids']
            print(f"üìÇ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•: {len(self.known_faces)} ‡∏Ñ‡∏ô")
            return True
        return False
    
    def recognize(self, frame, tolerance=0.6):
        """‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û"""
        # ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô
        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)
        rgb_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)
        
        # ‡∏´‡∏≤‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
        face_locations = face_recognition.face_locations(rgb_frame, model='hog')
        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)
        
        results = []
        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):
            # ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å
            matches = face_recognition.compare_faces(self.known_faces, face_encoding, tolerance=tolerance)
            face_distances = face_recognition.face_distance(self.known_faces, face_encoding)
            
            if len(face_distances) > 0:
                best_match_index = np.argmin(face_distances)
                
                if matches[best_match_index]:
                    student_id = self.known_ids[best_match_index]
                    confidence = 1 - face_distances[best_match_index]
                    
                    # ‡∏Ç‡∏¢‡∏≤‡∏¢‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏î‡∏¥‡∏°
                    top *= 4
                    right *= 4
                    bottom *= 4
                    left *= 4
                    
                    results.append({
                        'student_id': student_id,
                        'confidence': float(confidence),
                        'location': (top, right, bottom, left)
                    })
        
        return results
    
    def recognize_from_base64(self, image_data):
        """‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏à‡∏≤‡∏Å base64 image"""
        import base64
        
        if ',' in image_data:
            image_data = image_data.split(',')[1]
        
        nparr = np.frombuffer(base64.b64decode(image_data), np.uint8)
        frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        
        return self.recognize(frame)

# ‡∏™‡∏£‡πâ‡∏≤‡∏á instance
ai_face = AdvancedFaceRecognition()
